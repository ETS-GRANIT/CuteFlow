module finite_volumes_method
  implicit none
contains
  subroutine solve_finite_volumes
    use cudafor
    use mpi
    use precision_kind
    use global_data
    use global_data_device
    use file_id
    use pre_post_traitement
    use flux_riemann
    use cfl_condition
    use source_terms
    use memory_exchange_functions

    implicit none

    !*** Variables locales ***
    integer :: stat(MPI_STATUS_SIZE)
    integer :: nt, iter_nodes, iter_entree, cond_reg_perm

    type(dim3)      :: grid, tblock, grid_nodes, tblock_nodes, grid_edges, tblock_edges
    type(dim3)      :: block_copy, grid_copy , grid_halved, grid_reduc, tblock_reduc, grid_usc, tblock_usc
    real(fp_kind)   :: time_start, time_stop
    integer         :: ierr
    type(cudaEvent) :: startEvent , stopEvent

    tc          = 0.d0
    t_reg_perm  = 0.d0

    nt             = 0 
    cond_reg_perm  = 0

    allocate(resc_d(ndln,nelt), res_d(ndln,nelt))

    resc_d = 0.d0
    res_d = 0.d0

    allocate(sourcfric_d(ndln,nelt))
    allocate(sourcbath_d(ndln,nelt))
    allocate(io_identifier(nelt), io_identifier_d(nelt))

    allocate(afm1_d(nelt, 9))

    allocate(deltatmin_d(nelt-nelt_fant_recep))

    if (ndi>0) allocate(debit_entree_arr(ndi-1,2), debit_entree_arr_d(ndi-1,2))
    if (ndo>0) allocate(debit_sortie_arr(ndo-1),debit_sortie_arr_d(ndo-1))

    call get_io_index

    tblock = dim3(32, 1, 1)
    grid   = dim3(ceiling(real(nelt)/real(tblock%x)), 1, 1)
    grid_halved   = dim3(ceiling(real(nelt)/real(2*tblock%x)), 1, 1)

    tblock_reduc = dim3(1024, 1, 1)
    grid_reduc   = dim3(ceiling(real(nelt)/real(tblock_reduc%x)), 1, 1)

    block_copy = dim3(32,1,1) 
    grid_copy = dim3(ceiling(real(nelt)/real(block_copy%x)),1,1)

    tblock_edges = dim3(8, ns, 1)
    grid_edges   = dim3(ceiling(real(nelt)/real(tblock_edges%x)), 1, 1)

    tblock_usc = dim3(32, 1, 1)
    grid_usc   = dim3(ceiling(real(nmax_ptset)/real(tblock_usc%x)), nelt_fant_envoi_bloc, 1)

    if (solinit==1) then
      if (tc_init < TS) then
        tc = tc_init
      else
        print*,'TEMPS TOTAL DE SIMULATION INFERIEUR AU TEMPS DE LA SOLUTION INITIALE'
        tc = 0.
      endif
    endif    

    !!Initial dt exchange
    call cflcond<<<grid, tblock>>>(vdlg0_d,deltatmin_d)
    call reduction<<<grid_reduc, tblock_reduc, tblock_reduc%x*sizeof(deltatmin_d(1))>>>(deltatmin_d)
    if(num_mpi_process>1) call MPI_ALLREDUCE(MPI_IN_PLACE,dt_d,1,fp_kind_mpi,MPI_MIN,MPI_COMM_WORLD, mpi_ierr)
    ierr = cudaMemcpy(dt,dt_d,1)

    tc = 0.d0

    nt = 0

    ierr = cudaEventCreate(startEvent)
    ierr = cudaEventCreate(stopEvent)
    ierr = cudaEventRecord(startEvent,0)

    write(*,*) 'Loop over time starts' 
    do while ( (tc - ts + 2*tol ) < tol )
      nt = nt + 1

      ierr = cudaDeviceSynchronize()

      debit_entree  = 0.d0
      debit_sortie  = 0.d0

      call compute_flux<<<grid_edges, tblock_edges, ns*tblock_edges%x*sizeof(1.0d0), stream1>>>(surf_d,zm_d,vdlg_d)

      call compute_source_terms<<<grid, tblock, 0, stream2>>>(vdlg_d,surf_d,zm_d,deltatmin_d)

      if(ndo>1) then
        ierr = cudaMemcpyAsync(debit_sortie_arr,debit_sortie_arr_d,size(debit_sortie_arr),stream1)
        ierr = cudaStreamSynchronize(stream1)
        debit_sortie  =  debit_sortie + sum(debit_sortie_arr)
      end if

      if(ndi>1) then
        ierr = cudaMemcpyAsync(debit_entree_arr,debit_entree_arr_d,size(debit_entree_arr),stream1)
        ierr = cudaStreamSynchronize(stream1)
        !En fait on parcours les arretes numérote dans get_io_index
        do iter_nodes=1,ndi-1
          !!iter_entree = numero_ndinput(iter_nodes)
          iter_entree = debit_entree_arr(iter_nodes,2)
          debit_entree(iter_entree) = debit_entree(iter_entree) + debit_entree_arr(iter_nodes,1)
        end do
      end if

      !!Reduce sum of all debits
      if(num_mpi_process>1) then
        call MPI_ALLREDUCE(MPI_IN_PLACE,debit_entree,nombre_entrees,fp_kind_mpi,MPI_SUM,MPI_COMM_WORLD, mpi_ierr)
        call MPI_ALLREDUCE(MPI_IN_PLACE,debit_sortie,1,fp_kind_mpi,MPI_SUM,MPI_COMM_WORLD, mpi_ierr)
      end if

      ierr = cudaStreamSynchronize(stream1)
      call update_sol_with_flux_and_source<<<grid, tblock, 0, stream2>>>()

      if(num_mpi_process>1 .and. is_cgns==1) then
        call update_send_cells<<<grid_usc, tblock_usc, 0, stream2>>>()
      end if

      !!  Echange sur GPU directement bloc
      if(num_mpi_process>1) then
        if(cuda_aware==1) then
          if(is_cgns) then
            ierr = cudastreamsynchronize(stream2)
            call gpu_echange_cgns(vdlg_d, ndln)
          else
            call gpu_echange_fant_bloc_async(vdlg_d, ndln)
          end if
        else
          !!Not Cuda Aware version
          !! First copy from the GPU to CPU, then from CPU to CPU, ten from CPU to GPU
          ierr = cudaMemcpy(vdlg_d, vdlg, nelt*ndln, cudamemcpyDeviceToHost)
          ierr = cudadevicesynchronize()
          call gpu_echange_fant_bloc_async_not_cuda_aware(vdlg, ndln)
        end if
      end if

      !!Reset du pas de temps sur le gpu
      ! ierr = cudaStreamSynchronize(stream2)
      ! ierr = cudaMemcpyAsync(dt_d,dt_max,1,stream1) 
      ! Calcul du pas de temps via la CFL
      call cflcond<<<grid, tblock, 0, stream2>>>(vdlg_d,deltatmin_d)

      ! ierr = cudaStreamSynchronize(stream1) !! On peut commenter cette ligne pour faire le pari que la race condition sera ok

      call reduction<<<grid_reduc, tblock_reduc, tblock_reduc%x*sizeof(deltatmin_d(1)),stream2>>>(deltatmin_d)
      ! ierr = cudaMemcpyAsync(dt,dt_d,1,stream2)

      !!Take the smallest dt across all GPUs
      if(num_mpi_process>1) then
        ierr = cudaStreamSynchronize(stream2)
        ! call MPI_ALLREDUCE(MPI_IN_PLACE,dt,1,fp_kind_mpi,MPI_MIN,MPI_COMM_WORLD, mpi_ierr)
        call MPI_ALLREDUCE(MPI_IN_PLACE,dt_d,1,fp_kind_mpi,MPI_MIN,MPI_COMM_WORLD, mpi_ierr)
        ! ierr = cudaMemcpyAsync(dt_d,dt,1,stream2)
        ierr = cudaMemcpyAsync(dt,dt_d,1,stream2)
      end if

      !!Attendre fin de l'échange mémoire de vdlg
      !! et mise a jour vdlg avec vdlg
      if(num_mpi_process>1) then
        call MPI_WAITALL(size(reqsend),reqsend,sendstat,mpi_ierr)
        call MPI_WAITALL(size(reqrecv),reqrecv,recvstat,mpi_ierr)
        if(cuda_aware==0) then
          ierr = cudaMemcpy(vdlg, vdlg_d, nelt, cudamemcpyDeviceToHost)
        end if
      end if

      ierr = cudaMemcpyAsync(vdlg0_d, vdlg_d, ndln*nelt, stream1)

      if(dt>9999 .or. dt < 1e-15) then
        print*, "Erreur sur le pas de temps dt=", dt, " iteration= ", nt
        exit
      end if

      tc = tc + dt

      ! *** Affichage de l'avancement ***
      if ( mod(nt,freqaffich)==0 ) then
        print*,'-----------------------------------------------'
        write(*,*) 'nt = ', nt
        print*,' prochain tsolvisu = ', tsolvisu(cptsolvisu), cptsolvisu
        if (tc < 3600)   print*, 'tc = ', tc, ' Secondes   =>', tc/60,    ' Minutes' 
        if (tc >= 3600)  print*, 'tc = ', tc, ' Secondes   =>', tc/3600,  ' Heures'
        if (tc >= 86400) print*, 'tc = ', tc, ' Secondes   =>', tc/86400, ' Jours'
        print*,''

        do iter_entree=1,nombre_entrees
          print*, 'debit_entree ', iter_entree, " = " ,debit_entree(iter_entree)
        end do
        print*, 'debit_sortie =', debit_sortie, 'M3/S'  
        print*,'-----------------------------------------------'
      endif

      ! *** Stockage de la solution pour postraitement et animation 
      if((solvisu > 0 .and. abs( tc - tsolvisu(cptsolvisu) ) <= tolaffiche))then
        vdlg = vdlg_d
        ierr = cudadevicesynchronize()

        !Praview EXPORT
        if(solvisu==1 .or. solvisu==3) then
          call paraview_export(cptsolvisu)
        end if

        !CGNS EXPORT
        if(is_cgns==1 .and. (solvisu==2 .or. solvisu==3)) then
          call cgns_export(cptsolvisu)
        end if

        cptsolvisu = cptsolvisu + 1
      endif

      !Solsimple EXPORT
      if((solsimple /= 0 .and. abs( tc - tsolsimple(cptsolsimple) ) <= tolaffiche))then
        call simple_export(cptsolsimple)
        cptsolsimple = cptsolsimple + 1
      endif

      !STOCKAGE DE SOLUTIONS INTERMEDIAIRES  (Pour redemarrage)
      if(solrestart==1 .and. abs( tc - tsolrestart(cptsolrestart) ) <= tolaffiche) then
        call save_sol_for_restart
        cptsolrestart = cptsolrestart + 1
      endif

      debitglob_sum = sum(debitglob)
      debit_entree_sum = sum(debit_entree)

      if ( debit_entree_sum > 1e-8 .and. abs(debit_entree_sum - debit_sortie)/debit_entree_sum < tol_reg_perm ) then
        cond_reg_perm = cond_reg_perm + 1
        if( cond_reg_perm > 100000) then

          if ((60   <= tc) .and. (tc < 3600))   print*, 'tc = ', tc, ' Secondes   =>', tc/60,    ' Minutes' 
          if ((3600 <= tc) .and. (tc< 86400))  print*, 'tc = ', tc, ' Secondes   =>', tc/3600,  ' Heures'
          if (tc  >= 86400)        print*, 'tc = ', tc, ' Secondes   =>', tc/86400, ' Jours'
          print*,('')
          do iter_entree=1,nombre_entrees
            print*, 'debit_entree ', iter_entree, " = " ,debit_entree(iter_entree)
          end do
          print*, 'debit_sortie = ', debit_sortie
          print*, '' 
          print*, 'LE REGIME PERMANENT EST ATTEINT'
          print*,('================================================================================')

          t_reg_perm = tc
          tc   = tc + ts  ! pour sortir de la boucle while !to exit the while loop
        end if
      else
        cond_reg_perm = 0
      endif

    enddo 

    write(*,*) 'Loop on time ends at iteration : ', nt

    ierr = cudaEventRecord (stopEvent,0)
    ierr = cudaEventSynchronize(stopEvent)
    ierr = cudaEventElapsedTime(time_cuda, startEvent, stopEvent)

    vdlg = vdlg_d

    if(t_reg_perm>0.0d0) tc = t_reg_perm 

    if(sortie_finale_bluekenue) then
      call bluekenue_export
    end if

    if((solrestart==1 .and. abs( tc - tsolrestart(cptsolrestart) ) <= tolaffiche))then
      call save_sol_for_restart
      cptsolrestart = cptsolrestart + 1
    endif

    if(solsimple==1 .and. abs( tc - tsolsimple(cptsolsimple) ) <= tolaffiche) then
      call simple_export(cptsolsimple)
      cptsolsimple = cptsolsimple + 1
    endif

  end subroutine solve_finite_volumes

  attributes(global) subroutine update_sol_with_flux_and_source
    use precision_kind
    use global_data_device

    implicit none

    integer :: ti, gi
    real(fp_kind) :: resini(3)

    ti = threadIdx%x
    gi = (blockIdx%x - 1)*blockDim%x + ti

    if(gi <= nelt_d-nelt_fant_recep_d) then
      if ( friction_d == 1) then
        if ( fricimplic_d == 1 .or. fricimplic_d == 2 ) then
          resini = ( sourcbath_d(:,gi) + sourcfric_d(:,gi) - resc_d(:,gi) ) / surf_d(gi)
          res_d(1,gi) = sum(afm1_d(gi,1:3)*resini)
          res_d(2,gi) = sum(afm1_d(gi,4:6)*resini)
          res_d(3,gi) = sum(afm1_d(gi,7:9)*resini)
        else
          res_d(:,gi) = (sourcbath_d(:,gi)+ sourcfric_d(:,gi) - resc_d(:,gi)) / surf_d(gi)
        endif
      else 
        res_d(:,gi) = (sourcbath_d(:,gi) - resc_d(:,gi)) / surf_d(gi)
      endif

      vdlg_d(:,gi) = vdlg0_d(:,gi) + dt_d * res_d(:,gi)

      if(vdlg_d(1,gi) <= tolisec_d) then
        vdlg_d(1,gi) = tolisec_d
        vdlg_d(2,gi) = 0.
        vdlg_d(3,gi) = 0.
      end if
    endif
  end subroutine update_sol_with_flux_and_source

  subroutine get_io_index
    use precision_kind
    use global_data
    use global_data_device
    implicit none
    integer :: i, j, k, counter

    if(ndi>0) then
      debit_entree_arr = 0.d0
      debit_entree_arr_d = debit_entree_arr
    endif
    if(ndo>0) then
      debit_sortie_arr = 0.d0
      debit_sortie_arr_d = debit_sortie_arr
    endif

    io_identifier = 0

    counter = 1
    do i = 1, nelt
      if(boundary(i,1,1) == -1 .or. boundary(i,2,1) == -1 .or. boundary(i,3,1) == -1) then 
        io_identifier(i) =  counter
        counter = counter + 1
      endif
    enddo

    counter = 1
    do i = 1, nelt
      if(boundary(i,1,1) == -2 .or. boundary(i,2,1) == -2 .or. boundary(i,3,1) == -2) then 
        io_identifier(i) =  counter
        counter = counter + 1
      endif
    enddo

    io_identifier_d = io_identifier
    call cuda_glerror('get io index',1)
  end subroutine get_io_index
end module finite_volumes_method
